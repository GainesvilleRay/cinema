{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Code to format info on movies in a csv file for publication.\"\"\"\n",
    "\n",
    "# built-in libraries\n",
    "import csv\n",
    "from collections import OrderedDict, defaultdict\n",
    "import datetime\n",
    "from email.message import EmailMessage\n",
    "import os.path\n",
    "import re\n",
    "import smtplib\n",
    "import sqlite3\n",
    "import sys\n",
    "\n",
    "# installed with pip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from sqlalchemy import create_engine\n",
    "\n",
    "# Create list of dictionaries for each row.\n",
    "listings = []\n",
    "imacscrapedir = '/Users/rayd/workspace/cinema/scrapes/'\n",
    "airscrapedir = '/Users/Doug/workspace/cinema/scrapes/'\n",
    "scrapefile = 'fandango-2019-07-11.csv'\n",
    "scrape_path = airscrapedir + scrapefile\n",
    "with open(scrape_path, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        layout_dct = {\n",
    "            'addy': row[0],\n",
    "            'theater': row[1],\n",
    "            'title': row[2],\n",
    "            'mpaa': row[3],\n",
    "            'stars': row[4],\n",
    "            'times': row[5],\n",
    "            'format': row[6],\n",
    "            'synopsis': row[7],\n",
    "            'date': row[8],\n",
    "            'city': row[9]\n",
    "        }\n",
    "        listings.append(layout_dct)\n",
    "        \n",
    "del listings[0] #remove header row   \n",
    "      \n",
    "# Create Pandas dataframe for listings\n",
    "df = pd.DataFrame(listings)\n",
    "# Remove some duplicate listings\n",
    "#df = df[df.city != \"Belleview, FL\"]\n",
    "#df = df[df.city != \"High Springs, FL\"]\n",
    "#df = df[(df.city != \"The Villages, FL\") & (df.theater != \"Belleview Cinemas\")]\n",
    "#df = df[(df.city != \"The Villages, FL\") & (df.theater != \"Old Mill Playhouse\")]\n",
    "#df = df[(df.city != \"The Villages, FL\") & (df.theater != \"Old Mill Playhouse\")]\n",
    "# fix up titles, times and days, keep just needed columns, sort rows by movie+day\n",
    "df.title = df.title.apply(lambda x: '\"' + str(x) + '\"')\n",
    "df.times = df.times.str.replace(':00', '')\n",
    "df.times = df.times.str.replace('|', ',')\n",
    "df.times = df.times.str.replace('p', ' p.m.')\n",
    "df.times = df.times.str.replace('a', ' a.m.,')\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "df['movieday'] = df['date'].dt.weekday_name\n",
    "df = df.drop('city', axis=1)\n",
    "df = df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "df = df.drop('date', axis=1)\n",
    "df['screen'] = df['title'].str.cat(df['format'],sep=\", \")\n",
    "df.screen = df.screen.str.cat(df['mpaa'],sep=\", \")\n",
    "df = df[['theater', 'screen', 'movieday', 'times']]\n",
    "df.sort_values([\"screen\", \"movieday\"], axis =0,\n",
    "              ascending=True, inplace=True)\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Ocala market\n",
    "oc6_df = df.loc[df['theater'].str.contains('Ocala Center 6')]\n",
    "ocd_df = df.loc[df['theater'].str.contains('Drive-In')]\n",
    "bv_df = df.loc[df['theater'].str.contains('Belleview')]\n",
    "mt_df = df.loc[df['theater'].str.contains('Marion')]\n",
    "omp_df = df.loc[df['theater'].str.contains('Old Mill')]\n",
    "regaloca_df = df.loc[df['theater'].str.contains('Regal Hollywood')]\n",
    "rialto_df = df.loc[df['theater'].str.contains('Rialto')]\n",
    "amc_df = df.loc[df['theater'].str.contains('AMC Lake')]\n",
    "barn_df = df.loc[df['theater'].str.contains('Barnstorm')]\n",
    "\n",
    "# Gainesville market\n",
    "celeb_df = df.loc[df['theater'].str.contains('Celebration')]\n",
    "hipp_df = df.loc[df['theater'].str.contains('Hippodrome')]\n",
    "butler_df = df.loc[df['theater'].str.contains('Butler')]\n",
    "regalgnv_df = df.loc[df['theater'].str.contains('Regal Royal Park')]\n",
    "uac_df = df.loc[df['theater'].str.contains('Regal UA Cinema 90')]\n",
    "starke_df = df.loc[df['theater'].str.contains('Twin')]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>theater</th>\n",
       "      <th>screen</th>\n",
       "      <th>movieday</th>\n",
       "      <th>times</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Regal Celebration Pointe &amp; RPX</td>\n",
       "      <td>\"Aladdin (2019)\", Standard, PG</td>\n",
       "      <td>Friday</td>\n",
       "      <td>1:15 p.m. , 4:30 p.m. , 7:45 p.m. , 10:50 p.m.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Regal Celebration Pointe &amp; RPX</td>\n",
       "      <td>\"Aladdin (2019)\", Standard, PG</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1:15 p.m. , 4:30 p.m. , 7:45 p.m. , 10:50 p.m.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>Regal Celebration Pointe &amp; RPX</td>\n",
       "      <td>\"Aladdin (2019)\", Standard, PG</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>1:15 p.m. , 4:30 p.m. , 7:45 p.m. , 10:50 p.m.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Regal Celebration Pointe &amp; RPX</td>\n",
       "      <td>\"Annabelle Comes Home\", Standard, R</td>\n",
       "      <td>Friday</td>\n",
       "      <td>12:20 p.m. , 3:20 p.m. , 6:20 p.m. , 9:10 p.m.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>Regal Celebration Pointe &amp; RPX</td>\n",
       "      <td>\"Annabelle Comes Home\", Standard, R</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>12:20 p.m. , 3:20 p.m. , 6:20 p.m. , 9:10 p.m.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Regal Celebration Pointe &amp; RPX</td>\n",
       "      <td>\"Annabelle Comes Home\", Standard, R</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>12:20 p.m. , 3:20 p.m. , 6:20 p.m. , 9:10 p.m.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Regal Celebration Pointe &amp; RPX</td>\n",
       "      <td>\"Crawl (2019)\", Standard, R</td>\n",
       "      <td>Friday</td>\n",
       "      <td>12:05 p.m. , 2:30 p.m. , 4:55 p.m. , 7:20 p.m....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Regal Celebration Pointe &amp; RPX</td>\n",
       "      <td>\"Crawl (2019)\", Standard, R</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>12:05 p.m. , 2:30 p.m. , 4:55 p.m. , 7:20 p.m....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Regal Celebration Pointe &amp; RPX</td>\n",
       "      <td>\"Crawl (2019)\", Standard, R</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>12:05 p.m. , 2:30 p.m. , 4:55 p.m. , 7:20 p.m....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>Regal Celebration Pointe &amp; RPX</td>\n",
       "      <td>\"Spider-Man: Far From Home (2019)\", Digital 3D...</td>\n",
       "      <td>Friday</td>\n",
       "      <td>10:45 p.m.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>Regal Celebration Pointe &amp; RPX</td>\n",
       "      <td>\"Spider-Man: Far From Home (2019)\", Digital 3D...</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>10:45 p.m.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>Regal Celebration Pointe &amp; RPX</td>\n",
       "      <td>\"Spider-Man: Far From Home (2019)\", Digital 3D...</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>10:45 p.m.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>Regal Celebration Pointe &amp; RPX</td>\n",
       "      <td>\"Spider-Man: Far From Home (2019)\", Standard, ...</td>\n",
       "      <td>Friday</td>\n",
       "      <td>12:15 p.m. , 3:30 p.m. , 7 p.m. , 10:15 p.m. ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Regal Celebration Pointe &amp; RPX</td>\n",
       "      <td>\"Spider-Man: Far From Home (2019)\", Standard, ...</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>12:45 p.m. , 4 p.m. , 6:30 p.m. , 7:30 p.m. , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Regal Celebration Pointe &amp; RPX</td>\n",
       "      <td>\"Spider-Man: Far From Home (2019)\", Standard, ...</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>12:45 p.m. , 4 p.m. , 6:30 p.m. , 7:30 p.m. , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>Regal Celebration Pointe &amp; RPX</td>\n",
       "      <td>\"Stuber\", Standard, R</td>\n",
       "      <td>Friday</td>\n",
       "      <td>12 p.m. , 2:40 p.m. , 5:25 p.m. , 8:10 p.m. , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>Regal Celebration Pointe &amp; RPX</td>\n",
       "      <td>\"Stuber\", Standard, R</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>12 p.m. , 2:40 p.m. , 5:25 p.m. , 8:10 p.m. , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>Regal Celebration Pointe &amp; RPX</td>\n",
       "      <td>\"Stuber\", Standard, R</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>12 p.m. , 2:40 p.m. , 5:25 p.m. , 8:10 p.m. , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Regal Celebration Pointe &amp; RPX</td>\n",
       "      <td>\"The Secret Life of Pets 2\", Standard, PG</td>\n",
       "      <td>Friday</td>\n",
       "      <td>1:20 p.m. , 4:10 p.m.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Regal Celebration Pointe &amp; RPX</td>\n",
       "      <td>\"The Secret Life of Pets 2\", Standard, PG</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1:20 p.m. , 4:10 p.m.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Regal Celebration Pointe &amp; RPX</td>\n",
       "      <td>\"The Secret Life of Pets 2\", Standard, PG</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>1:20 p.m. , 4:10 p.m.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>Regal Celebration Pointe &amp; RPX</td>\n",
       "      <td>\"Toy Story 4\", Digital 3D, G</td>\n",
       "      <td>Friday</td>\n",
       "      <td>9 p.m.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Regal Celebration Pointe &amp; RPX</td>\n",
       "      <td>\"Toy Story 4\", Digital 3D, G</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>9 p.m.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>Regal Celebration Pointe &amp; RPX</td>\n",
       "      <td>\"Toy Story 4\", Digital 3D, G</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>9 p.m.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Regal Celebration Pointe &amp; RPX</td>\n",
       "      <td>\"Toy Story 4\", Standard, G</td>\n",
       "      <td>Friday</td>\n",
       "      <td>12:30 p.m. , 1 p.m. , 3:15 p.m. , 3:45 p.m. , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Regal Celebration Pointe &amp; RPX</td>\n",
       "      <td>\"Toy Story 4\", Standard, G</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>12:30 p.m. , 1 p.m. , 3:15 p.m. , 3:45 p.m. , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>Regal Celebration Pointe &amp; RPX</td>\n",
       "      <td>\"Toy Story 4\", Standard, G</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>12:30 p.m. , 1 p.m. , 3:15 p.m. , 3:45 p.m. , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Regal Celebration Pointe &amp; RPX</td>\n",
       "      <td>\"Yesterday (2019)\", Standard, PG-13</td>\n",
       "      <td>Friday</td>\n",
       "      <td>1:10 p.m. , 4:15 p.m. , 7:10 p.m. , 10 p.m.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Regal Celebration Pointe &amp; RPX</td>\n",
       "      <td>\"Yesterday (2019)\", Standard, PG-13</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1:10 p.m. , 4:15 p.m. , 7:10 p.m. , 10 p.m.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Regal Celebration Pointe &amp; RPX</td>\n",
       "      <td>\"Yesterday (2019)\", Standard, PG-13</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>1:10 p.m. , 4:15 p.m. , 7:10 p.m. , 10 p.m.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            theater  \\\n",
       "108  Regal Celebration Pointe & RPX   \n",
       "30   Regal Celebration Pointe & RPX   \n",
       "518  Regal Celebration Pointe & RPX   \n",
       "21   Regal Celebration Pointe & RPX   \n",
       "252  Regal Celebration Pointe & RPX   \n",
       "104  Regal Celebration Pointe & RPX   \n",
       "12   Regal Celebration Pointe & RPX   \n",
       "86   Regal Celebration Pointe & RPX   \n",
       "128  Regal Celebration Pointe & RPX   \n",
       "235  Regal Celebration Pointe & RPX   \n",
       "243  Regal Celebration Pointe & RPX   \n",
       "278  Regal Celebration Pointe & RPX   \n",
       "233  Regal Celebration Pointe & RPX   \n",
       "171  Regal Celebration Pointe & RPX   \n",
       "156  Regal Celebration Pointe & RPX   \n",
       "394  Regal Celebration Pointe & RPX   \n",
       "217  Regal Celebration Pointe & RPX   \n",
       "260  Regal Celebration Pointe & RPX   \n",
       "160  Regal Celebration Pointe & RPX   \n",
       "36   Regal Celebration Pointe & RPX   \n",
       "80   Regal Celebration Pointe & RPX   \n",
       "455  Regal Celebration Pointe & RPX   \n",
       "31   Regal Celebration Pointe & RPX   \n",
       "486  Regal Celebration Pointe & RPX   \n",
       "186  Regal Celebration Pointe & RPX   \n",
       "154  Regal Celebration Pointe & RPX   \n",
       "601  Regal Celebration Pointe & RPX   \n",
       "116  Regal Celebration Pointe & RPX   \n",
       "112  Regal Celebration Pointe & RPX   \n",
       "26   Regal Celebration Pointe & RPX   \n",
       "\n",
       "                                                screen  movieday  \\\n",
       "108                     \"Aladdin (2019)\", Standard, PG    Friday   \n",
       "30                      \"Aladdin (2019)\", Standard, PG  Saturday   \n",
       "518                     \"Aladdin (2019)\", Standard, PG    Sunday   \n",
       "21                 \"Annabelle Comes Home\", Standard, R    Friday   \n",
       "252                \"Annabelle Comes Home\", Standard, R  Saturday   \n",
       "104                \"Annabelle Comes Home\", Standard, R    Sunday   \n",
       "12                         \"Crawl (2019)\", Standard, R    Friday   \n",
       "86                         \"Crawl (2019)\", Standard, R  Saturday   \n",
       "128                        \"Crawl (2019)\", Standard, R    Sunday   \n",
       "235  \"Spider-Man: Far From Home (2019)\", Digital 3D...    Friday   \n",
       "243  \"Spider-Man: Far From Home (2019)\", Digital 3D...  Saturday   \n",
       "278  \"Spider-Man: Far From Home (2019)\", Digital 3D...    Sunday   \n",
       "233  \"Spider-Man: Far From Home (2019)\", Standard, ...    Friday   \n",
       "171  \"Spider-Man: Far From Home (2019)\", Standard, ...  Saturday   \n",
       "156  \"Spider-Man: Far From Home (2019)\", Standard, ...    Sunday   \n",
       "394                              \"Stuber\", Standard, R    Friday   \n",
       "217                              \"Stuber\", Standard, R  Saturday   \n",
       "260                              \"Stuber\", Standard, R    Sunday   \n",
       "160          \"The Secret Life of Pets 2\", Standard, PG    Friday   \n",
       "36           \"The Secret Life of Pets 2\", Standard, PG  Saturday   \n",
       "80           \"The Secret Life of Pets 2\", Standard, PG    Sunday   \n",
       "455                       \"Toy Story 4\", Digital 3D, G    Friday   \n",
       "31                        \"Toy Story 4\", Digital 3D, G  Saturday   \n",
       "486                       \"Toy Story 4\", Digital 3D, G    Sunday   \n",
       "186                         \"Toy Story 4\", Standard, G    Friday   \n",
       "154                         \"Toy Story 4\", Standard, G  Saturday   \n",
       "601                         \"Toy Story 4\", Standard, G    Sunday   \n",
       "116                \"Yesterday (2019)\", Standard, PG-13    Friday   \n",
       "112                \"Yesterday (2019)\", Standard, PG-13  Saturday   \n",
       "26                 \"Yesterday (2019)\", Standard, PG-13    Sunday   \n",
       "\n",
       "                                                 times  \n",
       "108     1:15 p.m. , 4:30 p.m. , 7:45 p.m. , 10:50 p.m.  \n",
       "30      1:15 p.m. , 4:30 p.m. , 7:45 p.m. , 10:50 p.m.  \n",
       "518     1:15 p.m. , 4:30 p.m. , 7:45 p.m. , 10:50 p.m.  \n",
       "21      12:20 p.m. , 3:20 p.m. , 6:20 p.m. , 9:10 p.m.  \n",
       "252     12:20 p.m. , 3:20 p.m. , 6:20 p.m. , 9:10 p.m.  \n",
       "104     12:20 p.m. , 3:20 p.m. , 6:20 p.m. , 9:10 p.m.  \n",
       "12   12:05 p.m. , 2:30 p.m. , 4:55 p.m. , 7:20 p.m....  \n",
       "86   12:05 p.m. , 2:30 p.m. , 4:55 p.m. , 7:20 p.m....  \n",
       "128  12:05 p.m. , 2:30 p.m. , 4:55 p.m. , 7:20 p.m....  \n",
       "235                                         10:45 p.m.  \n",
       "243                                         10:45 p.m.  \n",
       "278                                         10:45 p.m.  \n",
       "233  12:15 p.m. , 3:30 p.m. , 7 p.m. , 10:15 p.m. ,...  \n",
       "171  12:45 p.m. , 4 p.m. , 6:30 p.m. , 7:30 p.m. , ...  \n",
       "156  12:45 p.m. , 4 p.m. , 6:30 p.m. , 7:30 p.m. , ...  \n",
       "394  12 p.m. , 2:40 p.m. , 5:25 p.m. , 8:10 p.m. , ...  \n",
       "217  12 p.m. , 2:40 p.m. , 5:25 p.m. , 8:10 p.m. , ...  \n",
       "260  12 p.m. , 2:40 p.m. , 5:25 p.m. , 8:10 p.m. , ...  \n",
       "160                              1:20 p.m. , 4:10 p.m.  \n",
       "36                               1:20 p.m. , 4:10 p.m.  \n",
       "80                               1:20 p.m. , 4:10 p.m.  \n",
       "455                                             9 p.m.  \n",
       "31                                              9 p.m.  \n",
       "486                                             9 p.m.  \n",
       "186  12:30 p.m. , 1 p.m. , 3:15 p.m. , 3:45 p.m. , ...  \n",
       "154  12:30 p.m. , 1 p.m. , 3:15 p.m. , 3:45 p.m. , ...  \n",
       "601  12:30 p.m. , 1 p.m. , 3:15 p.m. , 3:45 p.m. , ...  \n",
       "116        1:10 p.m. , 4:15 p.m. , 7:10 p.m. , 10 p.m.  \n",
       "112        1:10 p.m. , 4:15 p.m. , 7:10 p.m. , 10 p.m.  \n",
       "26         1:10 p.m. , 4:15 p.m. , 7:10 p.m. , 10 p.m.  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "celeb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['theater'].str.contains('Rialto')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oc6_df = oc6_df.drop('theater', axis=1)\n",
    "#oc6_df.set_index('screen')\n",
    "#oc6_df.sort_values([\"screen\"], axis=0, \n",
    "#                 ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ocala market\n",
    "oc6_df.to_csv('outfiles/oc6.csv', index=False, header=False) # Ocala 6\n",
    "ocd_dr.to_csv('outfiles/ocd.csv', index=False, header=False) # Ocala Drive-in\n",
    "bv_df.to_csv('outfiles/bv.csv', index=False, header=False) # Belleview\n",
    "mt_df.to_csv('outfiles/mt.csv', index=False, header=False) # Marion\n",
    "omp_df.to_csv('outfiles/omp.csv', index=False, header=False) # Old Mill Playhouse\n",
    "regaloca_df.to_csv('outfiles/regaloca.csv', index=False, header=False) # Regal Hollywood\n",
    "rialto_df.to_csv('outfiles/rialto.csv', index=False, header=False) # Rialto\n",
    "amc_df.to_csv('outfiles/amc.csv', index=False, header=False) # AMC Lake Square 12\n",
    "barn_df.to_csv('outfiles/barn.csv', index=False, header=False) # Barnstorm\n",
    "\n",
    "# Gainesville market\n",
    "celeb_df.to_csv('outfiles/celeb.csv', index=False, header=False) # Celebration Pointe\n",
    "hipp_df.to_csv('outfiles/hipp.csv', index=False, header=False) # Hipp\n",
    "butler_df.to_csv('outfiles/butler.csv', index=False, header=False) # Regal Butler Town Center\n",
    "regalgnv_df.to_csv('outfiles/regalgnv.csv', index=False, header=False) # Regal Royal Park Stadium 17\n",
    "uac_df.to_csv('outfiles/uac.csv', index=False, header=False) # UA Cinema\n",
    "starke_df.to_csv('outfiles/starke.csv', index=False, header=False) # Florida Twin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index\n",
    "#oc6_df.set_index('screen', 'movieday')\n",
    "#oc6_df.set_index(['screen'], inplace=True)\n",
    "oc6_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('oc6.txt', oc6_df.values, fmt='%s', delimiter=',', newline='\\n', comments='#today')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oc6_list = oc6_df.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "for key, group in groupby(oc6_list, lambda x: x[0]):\n",
    "    listOfThings = \" and \".join([thing[1] for thing in group])\n",
    "    print(key + \", \" + listOfThings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "sizeofList = len(oc6_list) \n",
    "while i < sizeofList :\n",
    "    if oc6_list[i][0] == oc6_list[i+1][0] and oc6_list[i][2] == oc6_list[i+1][2]:\n",
    "        print(oc6_list[i][0] + \", \" + oc6_list[i][1] + \" at \" + oc6_list[i][2]) \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "sizeofList = len(oc6_list)\n",
    "sizeofList = 6\n",
    "while i < sizeofList :\n",
    "    if oc6_list[i][1] == \"Friday\" and oc6_list[i+1][1] != \"Saturday\":\n",
    "        print(\"It's a Friday only screening\")\n",
    "    elif oc6_list[i][1] == \"Friday\" and oc6_list[i+1][1] == \"Saturday\" and oc6_list[i+2][1] != \"Sunday\":\n",
    "        print(\"It's a Friday-Saturday screening\")\n",
    "    elif oc6_list[i][1] == \"Friday\" and oc6_list[i][1] == \"Saturday\" and oc6_list[i][1] == \"Sunday\":\n",
    "        print(\"We're here all weekend\")\n",
    "    elif oc6_list[i][1] == \"Saturday\" and oc6_list[i-1][1] != \"Friday\" and oc6_list[i+1]!= \"Sunday\":\n",
    "        print(\"It's a Saturday only screening\")\n",
    "    elif oc6_list[i][1] == \"Saturday\" and oc6_list[i+1][1] != \"Friday\" and oc6_list[i+2][1] == \"Sunday\":\n",
    "        print(\"It's a Saturday-Sunday screening\")\n",
    "    elif oc6_list[i][1] == \"Saturday\" and oc6_list[i-1][1] == \"Friday\" and oc6_list[i][1] == \"Sunday\":\n",
    "        print(\"We're here all weekend, but we're saying that again. Shall we drop this line?\")\n",
    "    elif oc6_list[i][1] == \"Sunday\" and oc6_list[i-1][1] != \"Saturday\":\n",
    "        print(\"It's a Sunday only screening\")\n",
    "    elif oc6_list[i][1] == \"Sunday\" and oc6_list[i-2][1] != \"Friday\" and oc6_list[i-1][1] == \"Saturday\":\n",
    "        print(\"It's a Saturday-Sunday screening, but we already said that. Shall we drop this line?\")\n",
    "        print(\"We're here all weekend, but we're saying that again. Shall we drop this line?\")\n",
    "    else:\n",
    "        print(\"This isn't working for some reason\")\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < 18:\n",
    "    if oc6_list[i][1] == \"Friday\" and oc6_list[i+1][1] == \"Saturday\" and oc6_list[i+2][1] == \"Sunday\":\n",
    "        print(\"We're here all weekend\")\n",
    "    elif oc6_list[i][1] == \"Friday\" and oc6_list[i+1][1] == \"Saturday\" and oc6_list[i+2][1] != \"Sunday\":\n",
    "        print(\"Looks like a Friday-Saturday screening.\")\n",
    "    elif oc6_list[i][1] == \"Friday\" and oc6_list[i+1][1] != \"Saturday\":\n",
    "        print(\"Looks like a Friday-only screening.\")\n",
    "    if oc6_list[i][1] == \"Saturday\" and oc6_list[i-1][1] == \"Friday\" and oc6_list[i+1][1] == \"Sunday\":\n",
    "        print(\"We're here all weekend\")\n",
    "    elif oc6_list[i][1] == \"Saturday\" and oc6_list[i-1][1] == \"Saturday\" and oc6_list[i+1][1] != \"Sunday\":\n",
    "        print(\"Looks like a Friday-Saturday screening, repeating.\")\n",
    "    elif oc6_list[i][1] == \"Saturday\" and oc6_list[i-1][1] != \"Friday\" and oc6_list[i][1] == \"Sunday\":\n",
    "        print(\"Looks like a Saturday-Sunday screening.\")\n",
    "    elif oc6_list[i][1] == \"Saturday\" and oc6_list[i-1][1] != \"Friday\" and oc6_list[i+1][1] != \"Sunday\":\n",
    "        print(\"Saturday only showing\")\n",
    "    else:\n",
    "        print(i)\n",
    "        \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < 18:\n",
    "    if oc6_list[i][] == \"Friday\" :\n",
    "        fri = oc6_list[i][1]\n",
    "    if oc6_list[i-1][1] == \"Friday\":\n",
    "        lastfri = oc6_list[i-1][1]\n",
    "    if oc6_list[i-1][1] == \"Saturday\":\n",
    "        lastsat = oc6_list[i-1][1]\n",
    "    if oc6_list[i-1][1] == \"Sunday\":\n",
    "        lastsun = oc6_list[i-1][1]\n",
    "    if oc6_list[i+1][1] == \"Friday\":\n",
    "        nextfri = oc6_list[i+1][1]\n",
    "    if oc6_list[i+1][1] == \"Saturday\":\n",
    "        lastsat = oc6_list[i-1][1]\n",
    "    if oc6_list[i+1][1] == \"Sunday\":\n",
    "        lastsun = oc6_list[i-1][1]\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KEEP THIS LOGIC\n",
    "\n",
    "moviedict = {\n",
    "    'Ocala6_AladinIMAX_Fri': {'times':'1, 2, 3'},\n",
    "    'Ocala6_AladinIMAX_Sat': {'times':'1, 2, 3'},\n",
    "    'Ocala6_AladinIMAX_Sun': {'times':'3, 2, 3'}\n",
    "}\n",
    "fri = str(moviedict['Ocala6_AladinIMAX_Fri']['times'])\n",
    "sat = str(moviedict['Ocala6_AladinIMAX_Sat']['times'])\n",
    "sun = str(moviedict['Ocala6_AladinIMAX_Sun']['times'])\n",
    "\n",
    "if fri == sat and fri == sun: # want all common\n",
    "    print(\"Friday-Sunday at \" + fri) \n",
    "elif fri != sat and fri != sun and sat == sun: # want fri unique\n",
    "    print(\"Friday at \" + fri + \", Saturday-Sunday at \" + sat)\n",
    "elif sat != fri and sat != sun and fri == sun: # want sat unique\n",
    "    print(\"Friday and Sunday at \" + fri + \", Saturday at \" + sat) \n",
    "elif sun != fri and sun != sat and fri == sat: # want sun unique\n",
    "    print(\"Friday and Saturday at \" + fri + \", Sunday at \" + sun)\n",
    "elif fri != sat and fri !=sun and sat !=sun: # want all unique\n",
    "    print(\"Friday at \" + fri + \", Saturday at \" + sat + \",Sundaay at\" + sun)\n",
    "else:\n",
    "    print(\"Show times didn't work out!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'outfiles/oc6.csv'\n",
    "\n",
    "with open(outfile) as csvfile:\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    screen = []\n",
    "    movieday = []\n",
    "    times = []\n",
    "    for row in readCSV:\n",
    "        screen = row[0]\n",
    "        movieday = row[1]\n",
    "        times = row[2]\n",
    "        \n",
    "    print(screen)\n",
    "    print(movieday)\n",
    "    print(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(outfile, \"r+\")\n",
    "ff = csv.reader(f)\n",
    "\n",
    "pre_line = ff.next()\n",
    "while(True):\n",
    "    try:\n",
    "        cur_line = ff.next()\n",
    "        if pre_line == cur_line:\n",
    "            pass #replace pass with do_something()\n",
    "        pre_line = cur_line\n",
    "    except:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'outfiles/oc6.csv'\n",
    "\n",
    "with open(outfile) as csvfile:\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    screen = []\n",
    "    movieday = []\n",
    "    times = []\n",
    "    for row in readCSV:\n",
    "        screen = row[0]\n",
    "        movieday = row[1]\n",
    "        times = row[2]\n",
    "        \n",
    "    print(screen)\n",
    "    print(movieday)\n",
    "    print(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ocala market\n",
    "oc6_df = df.loc[df['theater'] == 'Ocala Center 6']\n",
    "ocd_df = df.loc[df['theater'] == 'Ocala Drive-In']\n",
    "bv_df = df.loc[df['theater'] == 'Belleview Cinemas']\n",
    "mt_df = df.loc[df['theater'] == 'Marion Theatre']\n",
    "omp_df = df.loc[df['theater'] == 'Old Mill Playhouse']\n",
    "regaloca_df = df.loc[df['theater'] == 'Regal Hollywood Stadium 16 & IMAX - Ocala']\n",
    "rialto_df = df.loc[df['theater'] == 'Rialto Theatre Spanish Springs Town Square']\n",
    "amc_df = df.loc[df['theater'] == 'AMC Lake Square 12']\n",
    "barn_df = df.loc[df['theater'] == 'Barnstorm Theater']\n",
    "\n",
    "# Gainesville market\n",
    "celeb_df = df.loc[df['theater'] == 'Celebration Pointe 10']\n",
    "hipp_df = df.loc[df['theater'] == 'Hippodrome State Theatre']\n",
    "butler_df = df.loc[df['theater'] == 'Regal Butler Town Center 14']\n",
    "regalgnv_df = df.loc[df['theater'] == 'Regal Royal Park Stadium 16']\n",
    "uac_df = df.loc[df['theater'] == 'UA Cinema 90 6']\n",
    "starke_df = df.loc[df['theater'] == 'Florida Twin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocala_market = [oc6_df, bv_df, mt_df, omp_df, regaloca_df, amc_df, barn_df, rialto_df, ocd_df]\n",
    "gnv_market = [celeb_df, hipp_df, butler_df, regalgnv_df, uac_df, starke_df]\n",
    "\n",
    "ocadf = pd.concat(ocala_market)\n",
    "gnvdf = pd.concat(gnv_market)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocadf.to_csv('outfiles/oca.csv', index=False, header=False) # Ocala market\n",
    "gnvdf.to_csv('outfiles/gnv.csv', index=False, header=False) # Ocala 6\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['theater'] == 'Rialto Theatre Spanish Springs Town Square']alto_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['theater'].str.contains('Rialto')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = pd.DataFrame(data = {\n",
    "    'title' : ['AladinFri', 'AladinSat', 'AladinSun'],\n",
    "    'time' : ['3p', '3p', '3p']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AladinFri</td>\n",
       "      <td>3p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AladinSat</td>\n",
       "      <td>3p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AladinSun</td>\n",
       "      <td>3p</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       title time\n",
       "0  AladinFri   3p\n",
       "1  AladinSat   3p\n",
       "2  AladinSun   3p"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('title',\n",
       "              OrderedDict([(0, 'AladinFri'),\n",
       "                           (1, 'AladinSat'),\n",
       "                           (2, 'AladinSun')])),\n",
       "             ('time', OrderedDict([(0, '3p'), (1, '3p'), (2, '3p')]))])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict, defaultdict\n",
    "d = df_t.to_dict(into=OrderedDict)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friday at 3p\n",
      "Friday at 3p\n"
     ]
    }
   ],
   "source": [
    "for i in items[1][1]:\n",
    "    try:\n",
    "        if items[1][1][i] == items[1][1][i + 1]:\n",
    "            print(\"Friday at \" + items[1][1][i])\n",
    "        else:\n",
    "            print(\"different time this day\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AladinSat Friday-Sunday at 3p\n"
     ]
    }
   ],
   "source": [
    "if len(items[1][1]) == 3:\n",
    "    for i in items[1][1]:\n",
    "        fri = items[1][1][0]\n",
    "        sat = items[1][1][1]\n",
    "        sun = items[1][1][2]\n",
    "    \n",
    "        if fri == sat and fri == sun: # want all common\n",
    "            print(items[0][1][1] + \" Friday-Sunday at \" + fri)\n",
    "            break\n",
    "        elif fri != sat and fri != sun and sat == sun: # want fri unique\n",
    "            print(\"Friday at \" + fri + \", Saturday-Sunday at \" + sat)\n",
    "        elif sat != fri and sat != sun and fri == sun: # want sat unique\n",
    "            print(\"Friday and Sunday at \" + fri + \", Saturday at \" + sat) \n",
    "        elif sun != fri and sun != sat and fri == sat: # want sun unique\n",
    "            print(\"Friday and Saturday at \" + fri + \", Sunday at \" + sun)\n",
    "        elif fri != sat and fri !=sun and sat !=sun: # want all unique\n",
    "            print(\"Friday at \" + fri + \", Saturday at \" + sat + \",Sundaay at\" + sun)\n",
    "        else:\n",
    "            print(\"Show times didn't work out!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_celeb = celeb_df.to_dict(into=OrderedDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_celeb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
